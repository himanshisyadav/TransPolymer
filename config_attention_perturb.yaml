task: 'finetune'                                      # the task to visualize the attention scores
smiles: 'COCCOC$-1.84|C1COCO1$-0.53|COCCOCC(F)(F)F$6.54|NAN_SMILES$-0.09|[Li+].C(F)(F)(F)S(=O)(=O)[N-]S(=O)(=O)C(F)(F)F$0.27|0.65,0.84'
layer: 6                                              # the hidden layer for visualization when task=='pretrain'
index: 8                                              # the index of the sequence used for visualization when task=='finetune'
add_vocab_flag: True                                 # whether to add supplementary vocab

file_path: '/project/rcc/hyadav/TransPolymer_3/TransPolymer/data/random_test_exact_all_scaled_nonfusion_no_mol_new.csv'
vocab_sup_file: './data/vocab/vocab_sup_PE_I.csv'            # supplementary vocab file path
model_path: './ckpt/random_no_mol_scaled_new_linear_huber_5_temp_mul_768_nonfusion_new_best_model.pt'                # finetuned model path
pretrain_path: './ckpt/pretrain.pt'                     # pretrained model path
save_path: './figs/sa_map_pretrain_random_layer_6.png'                   # figure save path
blocksize: 9                                          # max length of sequences after tokenization
